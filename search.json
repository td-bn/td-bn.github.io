[
  {
    "objectID": "decentralization/btc/btc-timelocks.html",
    "href": "decentralization/btc/btc-timelocks.html",
    "title": "Timelocks",
    "section": "",
    "text": "Timelocks are restrictions on transactions or outputs that only allow spending after a point in time. Timelocks extend Bitcoin scripting in the dimension of time."
  },
  {
    "objectID": "decentralization/btc/btc-timelocks.html#transaction-locktime",
    "href": "decentralization/btc/btc-timelocks.html#transaction-locktime",
    "title": "Timelocks",
    "section": "Transaction Locktime",
    "text": "Transaction Locktime\nTransaction locktime is a transaction-level setting (a field in the transaction data structure) that defines the earliest time that a transaction is valid and can be relayed on the network or added to the blockchain.\nLocktime is also known as nLocktime from the variable name used in the Bitcoin Core codebase.\nIf nLocktime is nonzero and below 500 million, it is interpreted as a block height, meaning the transaction is not valid and is not relayed or included in the blockchain prior to the specified block height. If it is greater than or equal to 500 million, it is interpreted as a Unix Epoch timestamp (seconds since Jan-1-1970) and the transaction is not valid prior to the specified time\nNOTE: nLocktime has the limitation that while it makes it possible to spend some outputs in the future, it does not make it impossible to spend them until that time"
  },
  {
    "objectID": "decentralization/btc/btc-timelocks.html#check-lock-time-verify-cltv",
    "href": "decentralization/btc/btc-timelocks.html#check-lock-time-verify-cltv",
    "title": "Timelocks",
    "section": "Check Lock Time Verify (CLTV)",
    "text": "Check Lock Time Verify (CLTV)\nCLTV is a per-output timelock, rather than a per-transaction timelock as is the case with nLocktime. In simple terms, by adding the CLTV opcode in the redeem script of an output it restricts the output, so that it can only be spent after the specified time has elapsed.\nNOTE: While nLocktime is a transaction-level timelock, CLTV is an output-based timelock.\nCLTV doesn’t replace nLocktime, but rather restricts specific UTXO such that they can only be spent in a future transaction with nLocktime set to a greater or equal value.\nTo lock an output to a time, say 3 months from now, the transaction would be a P2SH transaction with a redeem script like this: <now + 3 months> CHECKLOCKTIMEVERIFY DROP DUP HASH160 <Payee Public Key Hash> EQUALVERIFY CHECKSIG\nNOTE: DROP pops from the stack"
  },
  {
    "objectID": "decentralization/btc/btc-timelocks.html#relative-timelocks",
    "href": "decentralization/btc/btc-timelocks.html#relative-timelocks",
    "title": "Timelocks",
    "section": "Relative Timelocks",
    "text": "Relative Timelocks\nnLocktime and CLTV are both absolute timelocks in that they specify an absolute point in time.\nRelative timelocks are useful because they allow a chain of two or more interdependent transactions to be held off chain, while imposing a time constraint on one transaction that is dependent on the elapsed time from the confirmation of a previous transaction. This functionality is especially useful in bidirectional state channels and Lightning Networks.\nRelative timelocks, like absolute timelocks, are implemented with both a transaction-level feature and a script-level opcode. The transaction-level relative timelock is implemented as a consensus rule on the value of nSequence, a transaction field that is set in every transaction input. Script-level relative timelocks are implemented with the CHECKSEQUENCEVERIFY (CSV) opcode.\n\nnSequence\nSince the activation of BIP-68, new consensus rules apply for any transaction containing an input whose nSequence value is less than 231 (bit 1<<31 is not set). Programmatically, that means that if the most significant bit (bit 1<<31) is not set, it is a flag that means “relative locktime.” Otherwise (bit 1<<31 set), the nSequence value is reserved for other uses such as enabling CHECKLOCKTIMEVERIFY, nLocktime, Opt-In-Replace-By-Fee, and other future developments.\nTransaction inputs with nSequence values less than 231 are interpreted as having a relative timelock. Such a transaction is only valid once the input has aged by the relative timelock amount. For example, a transaction with one input with an nSequence relative timelock of 30 blocks is only valid when at least 30 blocks have elapsed from the time the UTXO referenced in the input was mined. Since nSequence is a per-input field, a transaction may contain any number of timelocked inputs, all of which must have sufficiently aged for the transaction to be valid.\nThe nSequence value is specified in either blocks or seconds, but in a slightly different format than we saw used in nLocktime. A type-flag is used to differentiate between values counting blocks and values counting time in seconds. The type-flag is set in the 23rd least-significant bit (i.e., value 1<<22). If the type-flag is set, then the nSequence value is interpreted as a multiple of 512 seconds. If the type-flag is not set, the nSequence value is interpreted as a number of blocks. When interpreting nSequence as a relative timelock, only the 16 least significant bits are considered.\n\n\nCSV\nThe CSV opcode when evaluated in an UTXO’s redeem script allows spending only in a transaction whose input nSequence value is greater than or equal to the CSV parameter. Essentially, this restricts spending the UTXO until a certain number of blocks or seconds have elapsed relative to the time the UTXO was mined.\nAs with CLTV, the value in CSV must match the format in the corresponding nSequence value. If CSV is specified in terms of blocks, then so must nSequence. If CSV is specified in terms of seconds, then so must nSequence."
  },
  {
    "objectID": "decentralization/btc/btc-segwit.html",
    "href": "decentralization/btc/btc-segwit.html",
    "title": "SegWit",
    "section": "",
    "text": "Segregated Witness was an update to the Bitcoin consensus rules and network protocol that was activated on mainnet on August 1, 2017.\nWitness is referred to that which satisfies the cryptographic conditions placed in the UTXO.\nBefore segwit, witness data was embedded in the transaction as part of each input. The term segwit implies that we are segregating the witness from the transaction."
  },
  {
    "objectID": "decentralization/btc/btc-segwit.html#why-segwit",
    "href": "decentralization/btc/btc-segwit.html#why-segwit",
    "title": "SegWit",
    "section": "Why segwit?",
    "text": "Why segwit?\n\nTransaction Malleability\nWith segwit transaction hashes become immutable to anyone but the creator which has downstream effects for advanced transaction construction.\n\n\nScript Versioning\nEvery locking script is preceeded by a script version number. This allows the scripting language to be upgraded in a backward-compatible way.\n\n\nNetwork and Storage Scaling\nThe witness data is often a big contributor to the size of the transaction especially for multisigs and complex transactions with payment channels. By segregating the witness data, nodes can prune the witness data after validating the signature.\n\n\nSignature verification optimization\nSegwit upgraded signature functions to reduce complexity from \\(O(n^2)\\) to \\(O(n)\\) where n is number of signatures.\n\n\nOffline Signature Improvement\nSegwit signatures incorporate the value of each input in the hash that is signed. This makes streaming a large amount of data about previous transactions referenced as inputs redundant, improving offline signing.\nSince the amount is now part of the commitment hash that is signed, an offline device does not need the previous transactions. If the amounts do not match (are misrepresented by a compromised online system), the signature will be invalid"
  },
  {
    "objectID": "decentralization/btc/btc-segwit.html#segwit-transactions",
    "href": "decentralization/btc/btc-segwit.html#segwit-transactions",
    "title": "SegWit",
    "section": "Segwit Transactions",
    "text": "Segwit Transactions\n\nP2WPKH\nA simple P2PKH out script look like:\nDUP HASH160 ab68025513c3dbd2f7b92a94e0581f5d50f654e7 EQUALVERIFY CHECKSIG\nand the transaction data would look like:\n[...]\n“Vin” : [\n\"txid\": \"0627052b6f28912f2703066a912ea577f2ce4da4caa5a5fbd8a57286c345c2f2\",\n\"vout\": 0,\n         \"scriptSig\": “<Bob’s scriptSig>”,\n]\n[...]\nWith a segwit Pay-to-Witness-Public-Key-Hash this would look like:\n0 ab68025513c3dbd2f7b92a94e0581f5d50f654e7\nThe first number (0) is interpreted as a version number (the witness version) and the second part (20 bytes) is the equivalent of a locking script known as a witness program.\nThe 20-byte witness program is simply the hash of the public key, as in a P2PKH script.\nThe transaction data looks like:\n[...]\n“Vin” : [\n\"txid\": \"0627052b6f28912f2703066a912ea577f2ce4da4caa5a5fbd8a57286c345c2f2\",\n\"vout\": 0,\n         \"scriptSig\": “”,\n]\n[...]\n“witness”: “<Bob’s witness data>”\n[...]\nNote there is no signature in the Vin, whereas a separate witness field is present.\n\n\nP2WSH\nA simple P2SH out script look like:\nHASH160 54c557e07dde5bb6cb791c7a540e0a4796f5e97e EQUAL\nand the transaction data would look like:\n[...]\n“Vin” : [\n\"txid\": \"abcdef12345...\",\n\"vout\": 0,\n     \"scriptSig\": “<SigA> <SigB> <2 PubA PubB PubC PubD PubE 5 CHECKMULTISIG>”,\n]\nWith a segwit Pay-to-Witness-Script-Hash this would look like:\n0 a9b7b38d972cabc7961dbfbcb841ad4508d133c47ba87457b4a0e8aae86dbb89\nThe first number (0) is interpreted as a version number (the witness version) and the second part (32 bytes) hash of the hash of the redeem script.\nThe 20-byte witness program is simply the hash of the public key, as in a P2PKH script.\nThe transaction data looks like:\n[...]\n“Vin” : [\n\"txid\": \"abcdef12345...\",\n\"vout\": 0,\n         \"scriptSig\": “”,\n]\n[...]\n“witness”: “<SigA> <SigB> <2 PubA PubB PubC PubD PubE 5 CHECKMULTISIG>”\n[...]"
  },
  {
    "objectID": "decentralization/btc/btc-segwit.html#upgrading-to-segwit",
    "href": "decentralization/btc/btc-segwit.html#upgrading-to-segwit",
    "title": "SegWit",
    "section": "Upgrading to segwit",
    "text": "Upgrading to segwit\nNot all wallets and user facing applications will move to segwit at the same time. Backward compatibility needs to maintained.\n\nDifferentiating between P2WPKH and P2WSH\nThe critical difference between them is the length of the hash:\n\nThe public key hash in P2WPKH is 20 bytes\nThe script hash in P2WSH is 32 bytes\n\n\n\nSegwit scripts inside P2SH\nThis is made simpler by the fact that both form of witness scripts can be embedded inside the a P2SH address.\nThe users wallet creates a witness program. This witness program is then hashed. The resulting hash is embedded inside a P2SH script.\nThe P2SH hash is converted to a Bitcoin address(one that starts with a 3). This address can be shared be shared with anyone who wants to make a payment to the user, as if sending to a normal Bitcoin address.\nThis way both P2WSH and P2WPKH type payments can be used inside P2SH."
  },
  {
    "objectID": "decentralization/btc/btc-segwit.html#doubts",
    "href": "decentralization/btc/btc-segwit.html#doubts",
    "title": "SegWit",
    "section": "Doubts",
    "text": "Doubts\n\nHow does a legacy client see segwit transactions?"
  },
  {
    "objectID": "decentralization/btc/btc-transactions2.html",
    "href": "decentralization/btc/btc-transactions2.html",
    "title": "Bitcoin scripting",
    "section": "",
    "text": "Multisignature scripts set a condition where N public keys are recorded in the script and at least M of those must provide signatures to unlock the funds.\nThe locking script looks like:\n2 <Public Key A> <Public Key B> <Public Key C> 3 CHECKMULTISIG\nThe unlocking script can look something like:\n<Signature B> <Signature C>\nCombining the two, the validation script looks something like:\n<Signature B> <Signature C> 2 <Public Key A> <Public Key B> <Public Key C> 3 CHECKMULTISIG\nNOTE: There is a bug in the multisignature execution. It requires one extra argument. Convention is to use 0. So above actually looks like:\n0 <Signature B> <Signature C> 2 <Public Key A> <Public Key B> <Public Key C> 3 CHECKMULTISIG"
  },
  {
    "objectID": "decentralization/btc/btc-transactions2.html#pay-to-hash-scriptp2hs",
    "href": "decentralization/btc/btc-transactions2.html#pay-to-hash-scriptp2hs",
    "title": "Bitcoin scripting",
    "section": "Pay-to-hash-script(P2HS)",
    "text": "Pay-to-hash-script(P2HS)\nMultisignatures are cumbersome to use.\nIssues for payee:\n\nNeeds wallet software that can create custom transaction scripts\nscript is somewhat large and payer has to pay for the large size of the transaction\nUTXO is carried by the RAM of all nodes until spent\n\nP2HS was created to address these issues. The complex locking script is replaced with its digital fingerprint, a cryptographic hash. When a transaction attempting to spend the UTXO is presented later, it must contain the script that matches the hash, in addition to the unlocking script.\nP2SH means “pay to a script matching this hash, a script that will be presented later when this output is spent. In P2SH transactions, the locking script that is replaced by a hash is referred to as the redeem script because it is presented to the system at redemption time rather than as a locking script.\nThe locking script looks like:\nHASH160 <20-byte hash of redeem script> EQUAL\nThe unlocking script can look something like:\n0 Sig1 Sig2 <redeem script>\nwhere the redeem script can look something like:\n2 PubKey1 PubKey2 PubKey3 PubKey4 PubKey5 5 CHECKMULTISIG\nNOTE: Standard multisignature scripts can invalidate transactions by way of their locking or unlocking script, while P2SH scripts can invalidate transactions by way of their unlocking script only"
  },
  {
    "objectID": "decentralization/btc/btc-transactions2.html#p2sh-addresses",
    "href": "decentralization/btc/btc-transactions2.html#p2sh-addresses",
    "title": "Bitcoin scripting",
    "section": "P2SH Addresses",
    "text": "P2SH Addresses\nAnother important part of the P2SH feature is the ability to encode a script hash as an address(defined in BIP-13). P2SH addresses are Base58Check encodings of the 20-byte hash of a script, just like Bitcoin addresses are Base58Check encodings of the 20-byte hash of a public key. P2SH addresses use the version prefix “5,” which results in Base58Check-encoded addresses that start with a “3.”\nIt works in exactly the same way as a payment to a Bitcoin address.\nBenefits of P2SH:\n\nComplex scripts are replaced by shorter fingerprints in the transaction output, making the transaction smaller.\nScripts can be coded as an address, so the sender and the sender’s wallet don’t need complex engineering to implement P2SH.\nP2SH shifts the burden of constructing the script to the recipient, not the sender.\nP2SH shifts the burden in data storage for the long script from the output (which additionally to being stored on the blockchain is in the UTXO set) to the input (only stored on the blockchain).\nP2SH shifts the burden in data storage for the long script from the present time (payment) to a future time (when it is spent).\nP2SH shifts the higher transaction fee costs of a long script from the sender to the recipient, who has to include the long redeem script to spend it.\n\nNOTE: Because the redeem script is not presented to the network until you attempt to spend a P2SH output, if you lock an output with the hash of an invalid redeem script it will be processed regardless. The UTXO will be successfully locked. However, you will not be able to spend it because the spending transaction, which includes the redeem script, will not be accepted because it is an invalid script."
  },
  {
    "objectID": "decentralization/btc/btc-conditionals.html",
    "href": "decentralization/btc/btc-conditionals.html",
    "title": "Conditional Flows",
    "section": "",
    "text": "Conditional operators allows us to write scripts that have two ways of being unlocked, depending on whether the condition evluates to TRUE or FALSE.\nConditionals can be nested indefinitely, only limited by the maximum size of a script.\nOperators used to write conditionals are: IF, ELSE, ENDIF, NOTIF\nNote: In a stack based language like Bitcoin Script, the condition comes before the IF. e.g."
  },
  {
    "objectID": "decentralization/btc/btc-conditionals.html#verify-opcodes",
    "href": "decentralization/btc/btc-conditionals.html#verify-opcodes",
    "title": "Conditional Flows",
    "section": "VERIFY opcodes",
    "text": "VERIFY opcodes\nVerify means that if a condition is not TRUE, then the evaluation is stopped immediately.\nThus VERIFY suffixes act like guard clauses, continuing only if the pre-condition is met.\ne.g. redeem script with an EQUALVERIFY guard clause.\nHASH160 <expected hash> EQUALVERIFY <Bob's Pubkey> CHECKSIG\nThis can also be written using an IF instead:\nHASH160 <expected hash> EQUAL\nIF\n   <Bob's Pubkey> CHECKSIG\nENDIF\nNote\n\nthe VERIFY construction is more efficient, it uses two fewer opcodes.\nVERIFY opcodes do not leave anything on the stack, unlike say an EQUAL opcode."
  },
  {
    "objectID": "decentralization/btc/btc-conditionals.html#example-script-using-conditionals",
    "href": "decentralization/btc/btc-conditionals.html#example-script-using-conditionals",
    "title": "Conditional Flows",
    "section": "Example script using conditionals",
    "text": "Example script using conditionals\nFollowing is an example of a script with multiple outcomes:\n01  IF\n02    IF\n03      2\n04    ELSE\n05      <30 days> CHECKSEQUENCEVERIFY DROP\n06      <A's Pubkey> CHECKSIGVERIFY\n07      1\n08    ENDIF\n09    <M's Pubkey> <S's Pubkey> <Z's Pubkey> 3 CHECKMULTISIG\n10  ELSE\n11    <90 days> CHECKSEQUENCEVERIFY DROP\n12    <A's Pubkey> CHECKSIG\n13  ENDIF\nWe can evaluate the script in 3 ways:\n\n1. two of three multisig\nWe can unlock for 2 of 3 multisig using:\n0 <M's Sig> <Z's Sig> TRUE TRUE\nHere TRUE TRUE force evaluation of the nested if’s.\n\n\n2. one of three multisig + A’s Pubkey\nWe can use 1 of 3, along with A’s Pubkey using:\n0 <A's Sig> <S/M/Z's Sig> FALSE TRUE\n\n\n3. For A’s SIG only path\n<A's Sig> FALSE"
  },
  {
    "objectID": "decentralization/btc/btc-transactions.html",
    "href": "decentralization/btc/btc-transactions.html",
    "title": "Bitcoin Transactions",
    "section": "",
    "text": "Transaction outputs are indivisible chunks of bitcoin currency, recorded on the blockchain, and recognized as valid by the entire network.\nBitcoin full nodes track all available and spendable outputs, known as unspent transaction outputs, or UTXO.\nThe collection of all UTXO is known as the UTXO set and currently numbers in the millions of UTXO. The UTXO set grows as new UTXO is created and shrinks when UTXO is consumed. Every transaction represents a change (state transition) in the UTXO set.\n“received” bitcoin, what we mean is that the wallet has detected on the blockchain an UTXO that can be spent with one of the keys controlled by that wallet.\nA transaction output can have an arbitrary (integer) value denominated as a multiple of satoshis\n\nNOTE: Outputs are discrete and indivisible units of value, denominated in integer satoshis. An unspent output can only be consumed in its entirety by a transaction"
  },
  {
    "objectID": "decentralization/btc/btc-transactions.html#utxos",
    "href": "decentralization/btc/btc-transactions.html#utxos",
    "title": "Bitcoin Transactions",
    "section": "UTXOs",
    "text": "UTXOs\n\nUTXO are tracked by every full-node Bitcoin client in the UTXO set\nThe cryptographic puzzle is also known as a locking script, a witness script, or a scriptPubKey.\nEach output is defined by a value and a cryptographic puzzle.\n\n\nSerialization\n\nThe process of converting from the byte-stream representation of a transaction to a library’s internal representation data structure is called deserialization or transaction parsing."
  },
  {
    "objectID": "decentralization/btc/btc-transactions.html#transaction-inputs",
    "href": "decentralization/btc/btc-transactions.html#transaction-inputs",
    "title": "Bitcoin Transactions",
    "section": "Transaction Inputs",
    "text": "Transaction Inputs\n\nFor each UTXO that will be consumed to make this payment, the wallet creates one input pointing to the UTXO and unlocks it with an unlocking script.\nThe first part of an input is a pointer to an UTXO by reference to the transaction hash and an output index, which identifies the specific UTXO in that transaction.\nThe second part is an unlocking script, which the wallet constructs in order to satisfy the spending conditions set in the UTXO.\nThe third part is a sequence number\nNotice that because the value of the input is not explicitly stated, we must also use the referenced UTXO in order to calculate the fees that will be paid in this transaction\nWhen writing bitcoin software, anytime you decode a transaction with the intent of validating it or counting the fees or checking the unlocking script, your code will first have to retrieve the referenced UTXO from the blockchain in order to build the context implied but not present in the UTXO references of the inputs."
  },
  {
    "objectID": "decentralization/btc/btc-transactions.html#fees",
    "href": "decentralization/btc/btc-transactions.html#fees",
    "title": "Bitcoin Transactions",
    "section": "Fees",
    "text": "Fees\n\nMost transactions include transaction fees, which compensate the bitcoin miners for securing the network. Fees also serve as a security mechanism themselves, by making it economically infeasible for attackers to flood the network with transactions.\nfee relay policies are set by the minrelaytxfee option.\nThe current default minrelaytxfee is 0.00001 bitcoin or a hundredth of a millibitcoin per kilobyte. Therefore, by default, transactions with a fee less than 0.00001 bitcoin are treated as free and are only relayed if there is space in the mempool; otherwise, they are dropped\nMost services offer users the option of choosing high, medium, or low priority fees. High priority means users pay higher fees but the transaction is likely to be included in the next block. Medium and low priority means users pay lower transaction fees but the transactions may take much longer to confirm.\nTransaction fees are implied, as the excess of inputs minus outputs:\nthe fee is independent of the transaction’s bitcoin value."
  },
  {
    "objectID": "decentralization/btc/btc-transactions.html#transaction-scripts",
    "href": "decentralization/btc/btc-transactions.html#transaction-scripts",
    "title": "Bitcoin Transactions",
    "section": "Transaction Scripts",
    "text": "Transaction Scripts\n\nScript, the bitcoin scripting language is a Forth-like reverse-polish notation stack-based execution language\nBoth the locking script placed on an UTXO and the unlocking script are written in this scripting language.\nScript is a very simple language that was designed to be limited in scope and executable on a range of hardware, perhaps as simple as an embedded device\nmost transactions processed through the Bitcoin network have the form “Payment to Bob’s Bitcoin address” and are based on a script called a Pay-to-Public-Key-Hash script\nBitcoin transaction validation is not based on a static pattern, but instead is achieved through the execution of a scripting language.\n\n\nTuring incompleteness\n\nThe bitcoin transaction script language contains many operators, but is deliberately limited in one important way—there are no loops or complex flow control capabilities other than conditional flow control\n\n\n\nStateless verification\n\nThe bitcoin transaction script language is stateless, in that there is no state prior to execution of the script, or state saved after execution of the script."
  },
  {
    "objectID": "decentralization/btc/btc-transactions.html#construction",
    "href": "decentralization/btc/btc-transactions.html#construction",
    "title": "Bitcoin Transactions",
    "section": "Construction",
    "text": "Construction\n\nall the information needed to execute a script is contained within the script.\nBitcoin’s transaction validation engine relies on two types of scripts to validate transactions: a locking script and an unlocking script.\nA locking script is a spending condition placed on an output: it specifies the conditions that must be met to spend the output in the future.\nAn unlocking script is a script that “solves,” or satisfies, the conditions placed on an output by a locking script and allows the output to be spent.\nUnlocking scripts are part of every transaction input. Most of the time they contain a digital signature produced by the user’s wallet from his or her private key\nEvery bitcoin validating node will validate transactions by executing the locking and unlocking scripts together.\nThe validation software will copy the unlocking script, retrieve the UTXO referenced by the input, and copy the locking script from that UTXO. The unlocking and locking script are then executed in sequence. The input is valid if the unlocking script satisfies the locking script conditions"
  },
  {
    "objectID": "decentralization/btc/btc-transactions.html#script-execution",
    "href": "decentralization/btc/btc-transactions.html#script-execution",
    "title": "Bitcoin Transactions",
    "section": "Script Execution",
    "text": "Script Execution\n\nA stack allows two operations: push and pop.\nThe scripting language executes the script by processing each item from left to right. Numbers (data constants) are pushed onto the stack. Operators push or pop one or more parameters from the stack, act on them, and might push a result onto the stack. For example, OP_ADD will pop two items from the stack, add them, and push the resulting sum onto the stack.\nConditional operators evaluate a condition, producing a boolean result of TRUE or FALSE. For example, OP_EQUAL pops two items from the stack and pushes TRUE (TRUE is represented by the number 1) if they are equal or FALSE (represented by zero) if they are not equal. Bitcoin transaction scripts usually contain a conditional operator, so that they can produce the TRUE result that signifies a valid transaction.\nAlthough most locking scripts refer to a public key hash (essentially, a Bitcoin address), thereby requiring proof of ownership to spend the funds, the script does not have to be that complex.\nTransactions are valid if the top result on the stack is TRUE , any other nonzero value, not OP_0, or if the stack is empty after script execution. Transactions are invalid if the top value on the stack is FALSE (a zero-length empty value) or if script execution is halted explicitly by an operator, such as OP_VERIFY, OP_RETURN, or a conditional terminator such as OP_ENDIF\nthe unlocking script is executed, using the stack execution engine\nIf the unlocking script is executed without errors (e.g., it has no “dangling” pointers left over), the main stack is copied and the locking script is executed"
  },
  {
    "objectID": "decentralization/btc/btc-transactions.html#pay-to-public-key-hashp2pkh",
    "href": "decentralization/btc/btc-transactions.html#pay-to-public-key-hashp2pkh",
    "title": "Bitcoin Transactions",
    "section": "Pay-To-Public-Key-Hash(P2PKH)",
    "text": "Pay-To-Public-Key-Hash(P2PKH)\n<sig> <pubk> DUP HASH160 <pubkhash> EQUALVERIFY CHECKSIG\n\nThe vast majority of transactions processed on the Bitcoin network spend outputs locked with a Pay-to-Public-Key-Hash or “P2PKH” script.\nThese outputs contain a locking script that locks the output to a public key hash, more commonly known as a Bitcoin address.\nAn output locked by a P2PKH script can be unlocked (spent) by presenting a public key and a digital signature created by the corresponding private key\nthis combined script will evaluate to TRUE if, and only if, the unlocking script matches the conditions set by the locking script. In other words, the result will be TRUE if the unlocking script has a valid signature from the cafe’s private key that corresponds to the public key hash set as an encumbrance."
  },
  {
    "objectID": "decentralization/btc/btc-transactions.html#digital-signatures",
    "href": "decentralization/btc/btc-transactions.html#digital-signatures",
    "title": "Bitcoin Transactions",
    "section": "Digital Signatures",
    "text": "Digital Signatures\n\nECDSA is the algorithm used for digital signatures based on elliptic curve private/public key pairs,\nECDSA is used by the script functions OP_CHECKSIG, OP_CHECKSIGVERIFY, OP_CHECKMULTISIG, and OP_CHECKMULTISIGVERIFY.\nthe signature proves that the owner of the private key, who is by implication the owner of the funds, has authorized the spending of those funds\nthe proof of authorization is undeniable\nthe signature proves that the transaction (or specific parts of the transaction) have not and cannot be modified by anyone after it has been signed.\nNote that each transaction input is signed independently\n\nThis is critical, as neither the signatures nor the inputs have to belong to or be applied by the same “owners.”\n\nEach transaction input and any signature it may contain is completely independent of any other input or signature. Multiple parties can collaborate to construct transactions and sign only one input each.\n\nA digital signature is a mathematical scheme for demonstrating the authenticity of a digital message or documents\nA valid digital signature gives a recipient reason to believe that the message was created by a known sender (authentication), that the sender cannot deny having sent the message (nonrepudiation), and that the message was not altered in transit (integrity)"
  },
  {
    "objectID": "decentralization/btc/btc-transactions.html#math",
    "href": "decentralization/btc/btc-transactions.html#math",
    "title": "Bitcoin Transactions",
    "section": "Math",
    "text": "Math\n\nThe function Fsig produces a signature Sig that is composed of two values, commonly referred to as R and S:\nSig = (R, S)\nthey are serialized into a byte-stream using an international standard encoding scheme called the Distinguished Encoding Rules\nThe important numbers are R and S;\nThe signature verification algorithm takes the message (a hash of the transaction or parts of it), the signer’s public key and the signature (R and S values), and returns TRUE if the signature is valid for this message and public key.\nIn the simplest form, the signature applies to the entire transaction, thereby committing all the inputs, outputs, and other transaction fields\nHowever, a signature can commit to only a subset of the data in a transaction, which is useful for a number of scenarios as we will see in this section.\nBitcoin signatures have a way of indicating which part of a transaction’s data is included in the hash signed by the private key using a SIGHASH flag"
  },
  {
    "objectID": "decentralization/btc/btc-transactions.html#sighash",
    "href": "decentralization/btc/btc-transactions.html#sighash",
    "title": "Bitcoin Transactions",
    "section": "SIGHASH",
    "text": "SIGHASH\n\nThe SIGHASH flag is a single byte that is appended to the signature\nEvery signature has a SIGHASH flag and the flag can be different from input to input.\na transaction that contains several inputs may have signatures with different SIGHASH flags that commit different parts of the transaction in each of the inputs\nMany of the SIGHASH flag types only make sense if you think of multiple participants collaborating outside the Bitcoin network and updating a partially signed transaction.\nThere are three SIGHASH flags: ALL, NONE, and SINGLE\n\nNotes from bitcoinbook/ch06"
  },
  {
    "objectID": "decentralization/tbd/tdDEX.html",
    "href": "decentralization/tbd/tdDEX.html",
    "title": "tbDEX: Foundations, participants and flow",
    "section": "",
    "text": "The tbDEX protocol facilitates the formation of networks of mutual trust between counterparties that are not centrally controlled; it allows participants to negotiate trust directly with each other (or rely on mutually trusted third-parties to vouch for counterparties), and price their exchanges to account for perceived risk and specific requirements."
  },
  {
    "objectID": "decentralization/tbd/tdDEX.html#what-is-the-aim",
    "href": "decentralization/tbd/tdDEX.html#what-is-the-aim",
    "title": "tbDEX: Foundations, participants and flow",
    "section": "What is the aim?",
    "text": "What is the aim?\n\nbe a protocol for discovering liquidity and exchanging assets (such as bitcoin, fiat money, crypto assets or real world goods)\nutilize decentralized identity (DID) and verifiable credentials(VCs) to establish the provenance of identity in the real world\nprovides the infrastructure necessary to create a ubiquity of on-ramps and off-ramps directly between the fiat and crypto financial systems without the need for centralized intermediaries and trust brokers"
  },
  {
    "objectID": "decentralization/tbd/tdDEX.html#foundations",
    "href": "decentralization/tbd/tdDEX.html#foundations",
    "title": "tbDEX: Foundations, participants and flow",
    "section": "Foundations",
    "text": "Foundations\n\nDIDs\n\nare a new type of identifier that enables verifiable, decentralized digital identity\nA DID refers to any subject (e.g., a person, organization, thing, data model, abstract entity, etc.) determined by the controller of the DID.\nIn contrast to typical federated identifiers, DIDs have been designed so they may be decoupled from centralized registries, identity providers, and certificate authorities.\nwhile other parties may be used to help enable the discovery of information related to a DID, the design enables the owner of a DID to prove control over it without requiring permission from any other party\n\n\n\nVCs\n\nThe Verifiable Credentials specification provides a standard way to express credentials across the digital world in a way that is cryptographically secure, privacy respecting, and machine verifiable.\nZK tech can further advance privacy and safety by preventing linkability across disclosures, reducing the amount of data disclosed, and in some cases removing the need to expose raw data values at all.\n\n\n\nIdentity Hubs\n\nFor entities to exchange messages and data for credential, app, or service flows, they need an interface through which to store, discover, and fetch data related to the flows and experiences they are participating in\nIdentity Hubs are a data storage and message relay mechanism entities can use to locate public or permissioned private data related to a given DID\nThis enables the owning entity to secure, manage, and transact their data with others without reliance on location or provider-specific infrastructure, interfaces, or routing mechanisms.\nIdentity Hubs feature semantically encoded message and data interfaces that provide inferential APIs any party can interact with simply by knowing the semantic type of data they wish to exchange. A diverse set of interactions and flows can be modeled within these interfaces by externally codifying sets of message schemas and processing directives to form meta-protocols."
  },
  {
    "objectID": "decentralization/tbd/tdDEX.html#participants",
    "href": "decentralization/tbd/tdDEX.html#participants",
    "title": "tbDEX: Foundations, participants and flow",
    "section": "Participants",
    "text": "Participants\n\nIssuers of VCs\n\nIssuers are the source of VCs. Both individuals and organizations can be the source of VCs.\n\ne.g: a reputable organization that already conducts KYC checks could begin issuing a KYC credential to individuals\n\n\n\n\nParticipating Financial Institutions(PFIs)\n\nentities that provide liquidity services on the tdDEX network\neach PFI will be identified via DIDs and VCs\n\n\n\nWallets\n\nact as agents for individuals or institutions by facilitating exchanges with PFIs\nprovides:\n\nProviding secure encrypted storage for VCs\nPFI discovery by crawling identity hubs\napplying signatures and storing history"
  },
  {
    "objectID": "decentralization/tbd/tdDEX.html#protocol",
    "href": "decentralization/tbd/tdDEX.html#protocol",
    "title": "tbDEX: Foundations, participants and flow",
    "section": "Protocol",
    "text": "Protocol\nDivided into:\n\nRequest for Quote(RFQ): wallet broadcasts its intent to seek PFIs to exchange\nMessaging Protocol: P2P negotiation protocol which permits secure communication between a wallet and a PFI, to exchange required data and execute a transaction\n\n\nTopology and communication flow"
  },
  {
    "objectID": "decentralization/ln⚡/channel-construction.html",
    "href": "decentralization/ln⚡/channel-construction.html",
    "title": "Channel construction",
    "section": "",
    "text": "In the Lightning Network a combination of recorded (on-chain) and presigned but withheld (off-chain) transactions form a “layer” of payments that is a faster, cheaper, and more private way to use Bitcoin.\nIn a 2-of-2 scheme like that used in the Lightning Network, neither signer can spend the bitcoin without obtaining a signature from the other party.\nPayment channels in Lightning are based on a 2-of-2 multisig address, with the two channel partners as signers in the multisig."
  },
  {
    "objectID": "decentralization/ln⚡/channel-construction.html#identifying-nodes-on-ln",
    "href": "decentralization/ln⚡/channel-construction.html#identifying-nodes-on-ln",
    "title": "Channel construction",
    "section": "Identifying nodes on LN",
    "text": "Identifying nodes on LN\n\nEach node generates a root private key when first initialized.\nFrom that private key, the node derives a public key that is the node identifier and shared with the network.\nAdditionally, every node also advertises a network address where it can be reached, in one of several possible formats:\n\nCan be an IPv4/v6 address and a port number\nCab be an onion address and a port number\n\nThe network address identifier is written as Address:Port\n\n\nNode identifiers\nThe node public key and network address are written in the following format, separated by an @ sign, as NodeID@Address:Port. e.g.\n02a1cebfacb2674143b5ad0df3c22c609e935f7bc0ebe801f37b8e9023d45ea7b8 @172.16.235.20:9735"
  },
  {
    "objectID": "decentralization/ln⚡/channel-construction.html#constructing-a-channel",
    "href": "decentralization/ln⚡/channel-construction.html#constructing-a-channel",
    "title": "Channel construction",
    "section": "Constructing a channel",
    "text": "Constructing a channel\nChannel establishment is achieved by the exchange of six messages between Alice and Bob’s nodes (three from each peer): open_channel, accept_channel, funding_created, funding_signed, funding_locked, and funding_locked.\n[[Pasted image 20230130152720.png]]\nChannel establishment involves three parts: 1. First, the two peers communicate their capabilities and expectations, with Alice initiating a request through open_channel and Bob accepting the channel request through accept_channel. 2. Alice contructs the funding and refunding transactions, and sends the funding_created to Bob. Bob responds by sending back the necessary signature using funding_signed. Alice will now broadcast the funding transaction (on-chain) to establish and anchor the payment channel. The transaction will need to be confirmed on the Bitcoin blockchain 3. Once the transaction has sufficient confirmations (as defined by the minimum_depth field in the accept_channel message), Alice and Bob exchange funding_locked messages, and the channel enters normal operating mode."
  },
  {
    "objectID": "decentralization/ln⚡/channel-construction.html#constructing-a-refund-transaction",
    "href": "decentralization/ln⚡/channel-construction.html#constructing-a-refund-transaction",
    "title": "Channel construction",
    "section": "Constructing a refund transaction",
    "text": "Constructing a refund transaction\nAlice will construct the refund transaction immediately after constructing (but not broadcasting) the funding transaction. The refund transaction spends the 2-of-2 multisig back to Alice’s wallet. We call this refund transaction a commitment transaction because it commits both channel partners to distributing the channel balance fairly\nShe can do so because she can calculate the funding transaction’s hash and reference it as an input in the refund transaction.\nThis means that Alice can create a chained transaction by referencing an output that doesn’t yet exist, knowing that the reference will be valid if the funding transaction is confirmed, making the refund transaction valid too.\n\nChannel id\nThe channel ID is made by a bitwise “exclusive or” (XOR) of the funding transaction ID and output index:\nchannel_id = funding_txid XOR funding_output_index"
  },
  {
    "objectID": "decentralization/ln⚡/channel-construction.html#malleability-and-segwit",
    "href": "decentralization/ln⚡/channel-construction.html#malleability-and-segwit",
    "title": "Channel construction",
    "section": "Malleability and Segwit",
    "text": "Malleability and Segwit\nAlice has to depend on the transaction ID of the funding transaction being known before confirmation.\nBecause of the way transactions were constructed with the signatures (witnesses) included in the transaction ID, it was possible for a third party (e.g., Bob) to broadcast an alternative version of a transaction with a malleated (modified) transaction ID. This is known as transaction malleability, and prior to SegWit, this problem made it difficult to implement indefinite lifetime payment channels securely.\nNote, ECDSA signatures for a message are not unique. Knowing a signature (which is included in a valid transaction) allows one to produce many different-looking signatures that are still valid\nThe introduction of SegWit made unconfirmed transaction IDs immutable from the point of view of third parties, meaning that Alice could be sure that the transaction ID of the funding transaction would not change.\nBefore SegWit removed signatures from the transaction digest algorithm, Bob could replace the signature with an equivalent valid signature that produced a different transaction ID, breaking the chain between the funding transaction and the refund transaction."
  },
  {
    "objectID": "decentralization/ln⚡/sending-payments.html",
    "href": "decentralization/ln⚡/sending-payments.html",
    "title": "Sending Payments",
    "section": "",
    "text": "Sending a payment in a lightning channel is simply a matter of redistributing the balance of the channel.\nAll the two parties have to do is create and sign a transaction that spends the 2-of-2 multisig to two outputs paying the two parties their corresponding balances. This updated transaction is called a commitment transaction.\nOperating the payment channel is done by advancing the channel state through a series of commitments. Each commitment updates the balances to reflect payments that have flowed across the channel. Any party can initiate the commitment to update the state of the channel.\nEach signed and valid commitment transaction can be used by either channel partner at any time to close the channel by broadcasting it to the Bitcoin network.  Since they both have the most recent commitment transaction and can use it at any time, they can also just hold it and not broadcast it. It’s their guarantee of a fair exit from the channel.\nNo matter how many commitment transactions the parties construct and sign, only one of them can actually get confirmed.  As long as the parties hold these transactions and don’t broadcast them, the funding output is unspent."
  },
  {
    "objectID": "decentralization/ln⚡/sending-payments.html#cheating-with-old-commitments",
    "href": "decentralization/ln⚡/sending-payments.html#cheating-with-old-commitments",
    "title": "Sending Payments",
    "section": "Cheating with old commitments",
    "text": "Cheating with old commitments\nPreventing older commitment transactions from being used by the channel partners is done by a mechanism of revocation and penalties.\nNote only the last one accurately reflects the most recent channel balances.\n\nLightning protocol’s revocation and penalty mechanism\nConsists of three elements.\n\nAsymmetric commitment transactions\nEach party has a slightly different commitment transactions. They are not symmetric. The outputs that pay each channel partner are called to_localor to_self and to_remote, respectively. An invariant that the broadcasting party must always wait ensures that the “honest” party has time to refute the claim and revoke their funds.\n\n\nDelayed Spending\nThe payment to the party holding the commitment transaction is delayed (timelocked), whereas the payment to the other party can be claimed immediately. The to_local output is always timelocked and can’t be spent immediately, whereas the to_remote output is not timelocked and can be spent immediately. The delay is there for one reason: to allow the remote party to exercise a penalty option if an old (revoked) commitment should be broadcast by the other channel partner. Let’s look at the revocation keys and penalty option next.\nThe delay is negotiated during the initial channel construction message flow, as a field called to_self_delay.\n\n\nRevocation Keys\nUsed to unlock a penalty option for old commitments.\nThe way this works is that the to_local output is not only timelocked, but it also has two spending conditions in the script: it can be spent by self after the timelock delay or it can be spent by remote immediately with a revocation key for this commitment.\nA critical requirement to the security of this script is that the remote party cannot unilaterally sign with the revocationpubkey."
  },
  {
    "objectID": "decentralization/ln⚡/sending-payments.html#commitment-transaction",
    "href": "decentralization/ln⚡/sending-payments.html#commitment-transaction",
    "title": "Sending Payments",
    "section": "Commitment transaction",
    "text": "Commitment transaction\nThe first (to_local) output of a commitment transaction is defined as:\nOP_IF\n    # Penalty transaction\n    <revocationpubkey>\nOP_ELSE\n    <to_self_delay>\n    OP_CHECKSEQUENCEVERIFY\n    OP_DROP\n    <local_delayedpubkey>\nOP_ENDIF\nOP_CHECKSIG\nThe first clause allows the output to be spent by anyone who can sign for revocationpubkey.\nThe second clause is timelocked by to_self_delay blocks and can only be spent after that many blocks by anyone who can sign for local_delayedpubkey\nThe revocationpubkey  is derived for each state based on information from both the self (local) and remote party."
  },
  {
    "objectID": "decentralization/ln⚡/sending-payments.html#advancing-the-channel-state",
    "href": "decentralization/ln⚡/sending-payments.html#advancing-the-channel-state",
    "title": "Sending Payments",
    "section": "Advancing the channel state",
    "text": "Advancing the channel state\nTo advance the state of the channel, the local and remote parties exchange two messages: commitment_signed and revoke_and_ack messages.\nThe commitment_signed message can be sent by either channel partner when they have an update to the channel state.\nThe other channel partner then may respond with revoke_and_ack to revoke the old commitment and acknowledge the new commitment.\nWhen the other channel partner responds with revoke_and_ack they give the other partner a per_commitment_scret. This is used for the construction of the revocation key, which allows the honest party to penalize the cheating party."
  },
  {
    "objectID": "decentralization/ln⚡/routing.html",
    "href": "decentralization/ln⚡/routing.html",
    "title": "",
    "section": "",
    "text": "#bitcoin #bitcoindev #ln\nThe purpose of the LN is to enable off-chain transactions that are trusted just the same as the on-chain transactions because no one can cheat. The reason no one can cheat is because at any point anyone can take their transactions on-chain. The Bitcoin blockchain acts as a dispute-resolution and final settlement mechanism. The reason that any transaction can be kept off chain is precisely because at any point the transactions can be taken on-chain.\nAny Lightning node can route payments across its payment channels. Routing nodes cannot steal money while routing a payment. Routing nodes cannot lose money while participating in the routing process. They can choose to charge a fee for routing or do it for free. Due to onion routing, each node is only aware of the one node further in the route, and the previous node in the route.\nKey innovations of LN:"
  },
  {
    "objectID": "decentralization/ln⚡/routing.html#routing-vs-pathfinding",
    "href": "decentralization/ln⚡/routing.html#routing-vs-pathfinding",
    "title": "",
    "section": "Routing vs Pathfinding",
    "text": "Routing vs Pathfinding\nPathfinding refers to finding a series of payment channels that connect sender A to sender B.\nRouting refers to sending a payment across the network from A to B across the path found by pathfinding."
  },
  {
    "objectID": "decentralization/ln⚡/routing.html#fairness-protocol-for-sending-payments",
    "href": "decentralization/ln⚡/routing.html#fairness-protocol-for-sending-payments",
    "title": "",
    "section": "Fairness protocol for sending payments",
    "text": "Fairness protocol for sending payments\n\nProperties\nTrustless: The protocol can be trusted to prevent cheating.\nAtomic: Either the payment is fully executed, or it fails and everyone is refunded.\nMultihop: The security of a payment extends end to end for payments routed between channels, just as it is between a payment on a single channel."
  },
  {
    "objectID": "decentralization/ln⚡/routing.html#htlc-an-implementation-of-the-trustless-atomic-multihop-protocol",
    "href": "decentralization/ln⚡/routing.html#htlc-an-implementation-of-the-trustless-atomic-multihop-protocol",
    "title": "",
    "section": "HTLC: An implementation of the trustless, atomic, multihop protocol",
    "text": "HTLC: An implementation of the trustless, atomic, multihop protocol\nHTLC refers to hash time-locked contracts.\nHTLC uses a hash preimage as a secret that unlocks payments.\n\nThe recepient of the payment generates a random secret number and calculates its hash.\nThe hash becomes the condition for the of the payment, and once the secret is revealed, all the participants can redeem their incoming payments.\n\n\nPayment flow\nAlice requests an invoice from Dina. Inside the invoice is a payment hash. This is also called the payment pre-image.\nDina shares the hash of the secret with Alice.\n[[ln_routing_payment.excalidraw|600]]\nAlice will reimburse Bob with 12 gold coins if you can show a valid message that hashes to:_hash(R)_Bob has 24 hours to show the secret after the contract was signed. If Bob does not provide the secret by this time, Alice’s deposit will be refunded by the escrow service and the contract becomes invalid.\nBitcoin Script contract\n# To remote node with revocation key\nOP_DUP OP_HASH160 <RIPEMD160(SHA256(revocationpubkey))> OP_EQUAL\nOP_IF\n    OP_CHECKSIG\nOP_ELSE\n    <remote_htlcpubkey> OP_SWAP OP_SIZE 32 OP_EQUAL\n    OP_IF\n        # To local node via HTLC-success transaction.\n        OP_HASH160 <RIPEMD160(payment_hash)> OP_EQUALVERIFY\n        2 OP_SWAP <local_htlcpubkey> 2 OP_CHECKMULTISIG\n    OP_ELSE\n        # To remote node after timeout.\n        OP_DROP <cltv_expiry> OP_CHECKLOCKTIMEVERIFY OP_DROP\n        OP_CHECKSIG\n    OP_ENDIF\nOP_ENDIF"
  },
  {
    "objectID": "decentralization/ln⚡/routing.html#failures",
    "href": "decentralization/ln⚡/routing.html#failures",
    "title": "",
    "section": "Failures",
    "text": "Failures\nCooperative failures occur when the HTLC is unwound by every participant on the route, removing the HTLC output from the commitment messages without changing their balances.\nWhat if someone refuses to remove the HTLC? We have a timelock, which expires rendering the output unusable."
  },
  {
    "objectID": "rust/iter.html",
    "href": "rust/iter.html",
    "title": "Iterators",
    "section": "",
    "text": "See this for exercise.\nIterator in Rust is a trait. It has an associate type named Item and a method called next.\nItem is the type of item that the iterator will yield. It will call next and return items until they are exhausted at which point it returns None.\nIterators are also composable, and it’s common to chain them together to do more complex forms of processing."
  },
  {
    "objectID": "rust/iter.html#three-forms-of-iterators",
    "href": "rust/iter.html#three-forms-of-iterators",
    "title": "Iterators",
    "section": "Three forms of iterators",
    "text": "Three forms of iterators\nThree common ways to create iterators form a collection:\niter() // which iterates over &T.\niter_mut() // which iterates over &mut T.\ninto_iter() // which iterates over T."
  },
  {
    "objectID": "rust/iter.html#how-for-loop-works-under-the-hood",
    "href": "rust/iter.html#how-for-loop-works-under-the-hood",
    "title": "Iterators",
    "section": "How for loop works under the hood",
    "text": "How for loop works under the hood\nA for loop like\nfor x in vec![\"a\", \"b\", \"c\"] \n    ...\n}\nturns into something like:\nlet iter = vec![...].into_iter();\nwhile let Some(x) = iter.next() {\n    ...\n}\nIn actuality it is something like:\n    // let values = vec![...];\n    let result = match IntoIterator::into_iter(values) {\n        mut iter => loop {\n            let next;\n            match iter.next() {\n                Some(val) => next = val,\n                None => break,\n            };\n            let x = next;\n            // ....\n        },\n    };"
  },
  {
    "objectID": "rust/iter.html#into-iter",
    "href": "rust/iter.html#into-iter",
    "title": "Iterators",
    "section": "Into iter",
    "text": "Into iter\npub trait IntoIterator {\n    type Item;\n    type IntoIter: Iterator<Item = Self::Item>;\n\n    fn into_iter(self) -> Self::IntoIter;\n}\nSort of a wrapper trait around iter. Anything that can be turned into an iterator. Usually used for collections. By definiting IntoIter for a type, we define how it can be converted into an iterator.\nIn addition to an associated type Item, it also has an associtaed type IntoIter.\nIf a collection C implements iter(), it usually also implements IntoIterator for &C, with an implementation that just calles iter(). Likewise, a collection C that implements mut_iter(), it usually also implements IntoIterator for &mut C, with an implementation that just calles iter_mut().\nThis enables convenient shorthands like:\nlet mut values = vec![41];\nfor x in &mut values { // same as `values.iter_mut()`\n    *x += 1;\n}\nfor x in &values { // same as `values.iter()`\n    assert_eq!(*x, 42);\n}\nassert_eq!(values.len(), 1);"
  },
  {
    "objectID": "rust/iter.html#associated-type-vs-generic-type",
    "href": "rust/iter.html#associated-type-vs-generic-type",
    "title": "Iterators",
    "section": "Associated type vs generic type",
    "text": "Associated type vs generic type\nWhy do we have?\ntrait Iterator {\n   type Item;\n   ..\n}\nand not\ntrait Iterator<Item> {\n   ...\nBoth of these would work. An associated type is used when we expect there to be only one implementation of the trait for a given type.\ne.g. if we have an iterator type for a HashMap there is only one implementation for it keys and values.\nOn the other hand we want generic types for a trait when we expect to have multiple implementation for the same type.\ne.g a service trait that supports multiple types of requests.\nWhy don’t we use generic always? It saves the type checker some headache. We make its job easier. Reduces extra generic type params that we need to use."
  },
  {
    "objectID": "rust/iter.html#different-types-of-for-loops",
    "href": "rust/iter.html#different-types-of-for-loops",
    "title": "Iterators",
    "section": "Different types of for loops",
    "text": "Different types of for loops\n// General idea of Rust: being explicit is good\n\nfor v in vs {\n    // consumes vs and owned acess to v\n}\n\nfor v in vs.iter() {\n    // borrows vs, & to v\n}\n\nfor v in &vs {\n    // eq to vs.iter()\n}"
  },
  {
    "objectID": "rust/iter.html#other-method-in-iterator-trait",
    "href": "rust/iter.html#other-method-in-iterator-trait",
    "title": "Iterators",
    "section": "Other method in Iterator trait",
    "text": "Other method in Iterator trait\nProvides default implementation for other methods by using Item and next(). Note that Iterator provides a default implementation of methods such as nth and fold which call next internally. However, it is also possible to write a custom implementation of methods like nth and fold if an iterator can compute them more efficiently without calling next."
  },
  {
    "objectID": "rust/errors.html",
    "href": "rust/errors.html",
    "title": "Errors",
    "section": "",
    "text": "Two types of errors:"
  },
  {
    "objectID": "rust/errors.html#representing-errors",
    "href": "rust/errors.html#representing-errors",
    "title": "Errors",
    "section": "Representing Errors",
    "text": "Representing Errors\nDo we enumerate all possible errors so that the caller can distinguish them or do we provide a single opaque error.\n\nEnumeration\nThe user needs to be able to distinguish between different error cases so that they can respond accordingly. So we use an enum.\nWhen making our own error types we should take care to:\n\nError type should implement the std::error::Error trait, which provides callers with common methods for introspecting error types. e.g. Error::source method a mechanism to find the source of the underlying error. This is most commonly used to trace the error to the source cause.\nThe type should implement both Display and Debug so that the caller can print meaningful messages. The rule of thumb is a line describing the error for the Display implementation and more descriptive error including information that can help in debugging for the Debug implementation.\nWherever possible it should implement both Send and Sync, so that users can share the errors across thread boundaries.\nWherever possible the error type should be 'static This allows the user to easily propagate the error up and down the stack without running in to lifetime issues. It also enable the error to be used more easily with type-erased error types.\n\npub enum FileCopyError {\n    In(std::io::Error),\n    Out(std::io::Error),\n}\nPlayground example of error enumeration.\n\n\nOpaque Errors\nSometime the application using your code can’t meaningfully recover from the error, even if knows exactly the source of the error. In cases like this we want to provide a single opaque error type.\nThe error should implement Send, Sync, Display, Debug, and Error (including the sources method). Internally we might want to represent more fine-grained details, but there is no need to expose those to the users of the library.\nExactly how opaque error type should be is mostly up to us. - it could be a type with all private fields that exposes only limited methods for displaying and introspecting the error - it could be a severely type-erased error type like Box<dyn Error + Send + Sync + 'staic>, which reveals nothing more than the fact that it is an error and does not generally allow introspection.\nUsing Box<dyn Error> leaves users with little choice but to bubble up the error.\nType-erased errors often compose nicely and allow expression of an open-ended errors. We can easily combine errors from different sources without having to introduce additional error types.\ne.g.  If we write a function whose return is Box<dyn Error + ...> the we can use ? across different errors types inside that function, on all sorts of errors and they can all be turned into a common error type.\n’static bound in Box<dyn Error ..> allows\n\nthe propagation of errors without worrying about the lifetime bounds of that method that failed\naccess to downcasting\n\n\n\nDowncasting\nDowncasting is the process of taking an item of one type and casting it to a more specific type.\nIn the context of errors, downcasting allows a user to tuen a dyn Error into a concrete underlying error type when the dyn Error was originally of that type.\nThe downcast_ref method returns an Option which tells the user whether or not the downcast succeed. This method only if the argument is 'static. If we return an opaque Error that is not 'static we take away the user’s ability to do this kind of error introspection should they wish.\nSee docs for trait Any"
  },
  {
    "objectID": "rust/errors.html#propagating-errors",
    "href": "rust/errors.html#propagating-errors",
    "title": "Errors",
    "section": "Propagating Errors",
    "text": "Propagating Errors\nRust’s ? operator acts as a shorthand for unwrap of return early when working with Errors.\n?:\n\nperforms type conversion through the From trait\nin a function that returns Result<T, E> we can use ? on any Result<T, X> where E: From<X>.\n\nThis feature makes error erasure through Box<dyn Error> so appealing. We can just use ? everywhere without having to worry about the particular error type.\n\nNOTE: The ? operator is just syntax sugar for a trait tentatively called Try. See: https://doc.rust-lang.org/std/ops/trait.Try.html\n\nSee playground example"
  },
  {
    "objectID": "rust/chanells.html",
    "href": "rust/chanells.html",
    "title": "Channels and sync primitives",
    "section": "",
    "text": "Channels gives us handles for sender(s) and a receiver. Sender(s) can send the data and the Receiver can receive the data.\nRust provides mpsc(multiple producer, single consumer) channels in the std lib.\nSee this for simple Async channel implementation using Rust sync primitives."
  },
  {
    "objectID": "rust/chanells.html#types-of-channels",
    "href": "rust/chanells.html#types-of-channels",
    "title": "Channels and sync primitives",
    "section": "Types of channels",
    "text": "Types of channels\n\nAsynchronous Infinite capacity. Non blocking send. Uses Sender.\nSynchronous Fixed size buffer. Blocking till buffer space available. Uses SyncSender.\n\nBoth Senders are clonable such that multiple threads can simultaneoulsy send to a single consumber.\nIn both of these channels all data created on the Sender half will become available on the Receiver in the same order that it was sent. The Sender can be cloned but only one Receiver is supported."
  },
  {
    "objectID": "rust/chanells.html#useful-primitives-used-in-channel-implementations",
    "href": "rust/chanells.html#useful-primitives-used-in-channel-implementations",
    "title": "Channels and sync primitives",
    "section": "Useful primitives used in channel implementations",
    "text": "Useful primitives used in channel implementations\n\nMutex\nA mutual exclusion primitive for protecting shared data.\nThis mutex will block threads waiting for the lock to become available.\nThe data can only be accessed through the RAII guards returned from lock and try_lock, which guarantees that the data is only ever accessed when the mutex is locked.\n\n\nCondvar\nA conditional variable which represents the ability to block a thread such that it consumes no CPU time while waiting for an event to occur.\nCondition variables are typically associated with a boolean predicate (a condition) and a mutex. The predicate is always verified inside of the mutex before determining that a thread must block.\n.wait : Blocks the current thread until this condition variable receives a notification.\n.notify_one: Wakes up one blocked thread on this condvar.\n\n\nArc\nA thread-safe reference-counting pointer. ‘Arc’ stands for ‘Atomically Reference Counted’.\nThe type Arc<T> provides shared ownership of a value of type T, allocated in the heap."
  },
  {
    "objectID": "rust/types-alignment-and-layout.html",
    "href": "rust/types-alignment-and-layout.html",
    "title": "Alignment and memory layout of types",
    "section": "",
    "text": "Rust value has a type. One of the most fundamental role of types is to tell how to reference bits in memory.\ne.g. 0b11011101 can have different values based on whether this is interpreted as a u32 of an i32."
  },
  {
    "objectID": "rust/types-alignment-and-layout.html#alignment",
    "href": "rust/types-alignment-and-layout.html#alignment",
    "title": "Alignment and memory layout of types",
    "section": "Alignment",
    "text": "Alignment\nAlignment dictates where the bytes for a type can be stored.\nNote pointers point to bytes not bits. For this reason they must start at a byte boundary. This means that all pointers must be byte aligned i.e. they must be placed at an address that is a multiple of 8.\nWhenever possible we want to ensure that the hardware is operating in its native alignment. For 64 bit CPUs, most values are accessed in 8 byte words, hence most operations start at a 8-byte-aligned address.\n\ne.g. it would be silly to have a u64 spanning across two 8-byte words. It would be ineffiencient for the CPU to read this as compared to one that is in a single word.\n\nCPU operations require or strongly prefer that their arguments are naturally aligned. Since naturally aligned access provides better performance and other advatages, the compiler tries to take advantage of these properties. It gives every type an alignment that’s computed based on the types that it contains.\nBuilt in types are usually aligned to their size. e.g > a u8 is byte-aligned, u16 is two byte-aligned and so on\nComplex types are typically assigned the largest alignment of the types they contain. > a type containing a u8, u16 and a u32 will be 4-byte aligned"
  },
  {
    "objectID": "rust/types-alignment-and-layout.html#layout",
    "href": "rust/types-alignment-and-layout.html#layout",
    "title": "Alignment and memory layout of types",
    "section": "Layout",
    "text": "Layout\nLayout refers to the in-memory representation of the type. Rust provides a repr attribute that can be used on type definitions to request a particular memory layout.\nstruct Foo {\n  tiny: bool,\n  normal: u32,\n  small: u8,\n  long: u64,\n  short: u16,\n\n}\n\nrepr(C)\nThe most common one is repr(C) which lays out the type in a way that is compatible with how a C or C++ compiler would lay out the same type. This is useful when writing Rust code that interfaces with foreign-function interfaces.\nSee: representation of a struct using repr(C)\nNote: Foo takes 32 bytes in the above example.\nOne of the limitations is that this requires that we place all fields in the same order that they appear in the original struct definition.\n\n\nrepr(Rust), the default Rust representation\nDoes not provide guarantees for deterministic field ordering for types that happen to have the same fields. Also doesn’t follow the representation of fields in the same order that they have been defined in.\nCan reorder fields, which means that they can be placed in decreasing order of size. This allows for no padding in the above example. The fields themselves can be used to achieve the necessary alignment.\nSee: representation of a struct using repr(Rust)\nNote: Foo takes 16 bytes in the above example.\n\n\nrepr(packed)\nTells the compiler that we do not want any padding between our fields. This implies that we are willing to take the performance hit of using misaligned accesses.\nSee: representation of a struct using repr(packed)\nNote: Foo takes 16 bytes in the above example.\n\n\nOther options\n\nrepr(transparent) Used on types with a single field which guarantees that the layout of the outer type is the same as the inner type.\nrepr(align(n)) When we want to give a particular field a larger alignment that it required. A common use for this is to ensure that values stored in contiguous memory end up in different cache lines in the CPU. (Helps avoid false sharing.)"
  },
  {
    "objectID": "rust/coherance-and-orphan-rules.html",
    "href": "rust/coherance-and-orphan-rules.html",
    "title": "Coherence and Orphan Rules",
    "section": "",
    "text": "Rust traits can be generic in two ways: 1. with generic type parameters trait Foo<T> 2. with associated types trait Foo { type Bar; }\nWith the generic trait, users must always specify the generic parameters and repeat any bounds on those parameters. If we add a generic parameter to a trait, all users of that trait must also be updated to reflect the change. The upside is that the trait can be implemented multiple times for the same type: e.g. one can implement both FromIterator<T> and FromIterator<&T> where T: Clone , precisely because of the flexibility that generic traits provide.\nAssociated traits are easier to work with but will not allow multiple implementations. The compiler needs to know only the type that implements the trait, and the associated traits follow. This means that the bounds can live within the trait itself and do not need to be repeated on use.\n\nNote: one cannot implement Deref against multiple Target types, not can one implement Iterator with multiple different Item types."
  },
  {
    "objectID": "rust/coherance-and-orphan-rules.html#coherence-and-orphan-rule",
    "href": "rust/coherance-and-orphan-rules.html#coherence-and-orphan-rule",
    "title": "Coherence and Orphan Rules",
    "section": "Coherence and orphan rule",
    "text": "Coherence and orphan rule\n\nFor any given type and method, there is only ever one correct choice for which implementation of the method to use for that type.\n\nImagine what would happen if we wrote out own Display implementation for the bool type. The compiler wouldn’t know which implementation to use.\nA way to uphold the coherence rule would be ensure that only the create that defines a trait can write implementations for that trait. But this would make traits useless, as there would be no way to implement traits like Debug for our own types.\nAnother way could be to to allow implementation of traits for only own own types. But that means that a create defines a trait cannot provide implementations for types in the standard library.\nWe ideally want a set of rules so that: - allow downstream creates to implement upstream traits for their types - allow upstream crates to add implementation of their own traits without breaking downstream code\nThe orphan rules establishes this balance. > One can implement a trait for a type only if the trait or the type is local to ones crate.\n\nBlanket implementations\nimpl<T> MyTrait for T where T:..\nThese sort of blanket implementations are only allowed for crates that define a trait.\nAdding a blanket implementation is considered to be breaking code. This is because a downstream implementation would now stop compiling because of conflicting implementations.\n\n\nFundamental types\nSome types are so essential that it is necessary to allow anyone to implement traits on them, even if the seemingly violate the orphan rules.\nThese include: &, &mut and Box.\nAdding a blanked implementation over a fundamental type is also considered a breaking change.\n\n\nCovered Implementations\nimpl<P1...=Pn> ForeignTrait<T1..=Tn> for T0 Implementation of foreign traits for foreign types is allowed under specific circumstances: - at least one Ti is a local type - no T before Ti is one of the generic types P1..=Pn - a T is allowed to appear in T0..Ti as long as they are covered by some intermediate type.\nA T is covered if it appears as a type parameter to some other type e.g. Vec<T> but not if it stands on its own, or just appears behind a fundamental type like &T\ne.g. valid implementations\nimpl<T> From<T> for MyType\nimpl<T> From<T> for MyType<T>\nimpl<T> From<MyType> for Vec<T>\nimpl<T> ForeignTrait<MyType, T> for Vec<T>\ne.g. invalid implementations:\nimpl<T> ForeignTrait for T\nimpl<T> From<T> for T\nimpl<T> From<Vec<T>> for T\nimpl<T> From<MyType<T>> for T\nimpl<T> From<T> for Vec<T>\nimpl<T> ForeignTrait<T, MyType> for Vec<T>"
  },
  {
    "objectID": "rust/foundations.html",
    "href": "rust/foundations.html",
    "title": "",
    "section": "",
    "text": "Values in Rust are a combination of a type and an element in the domain of that type.\nValues are stored at a place which can be the stack, the heap or any other location.\nA pointer points to such a place. It holds the address of a region of memory.\nThe most common way to store a value is on a named value slot on the stack. We refer to this named value slot by a variable.\n\nNote: We can store the same pointer in more than one variable and thus have multiple variables that indirectly refer to the same location in memory, and thus the same underlying value.\n\n\n\n\nIn a high level model of a variable, we can think of variables as name given to a value. When we assign a value to a variable, then that value from then on is named by that variable.\nA good mental model is to imagine a dependency relationship being created between two successive access of a variable. When a variable is moved, no dependency can be mapped to it. A dependency relationship cannot be mapped from a variable that isn’t there(hasn’t been initliazed or has been moved).\nThe dependency relationships or flows trace the lifetimes of a particular instance of a value.\nThis roughly matches roughly how the compiler and the borrow checker reason about the program.\n\n\n\nVariables name memory locations that may or may not hold legal values.\nlet x: u32; // x is a name for a region in memory\nx = 6; // value 6 written to address\nIf we declare multiple variables with the same names they end up at different memory locations.\n\n\n\n\n\nStack is a region of memory that is used by a program as a scratch space for function calls. Every time a function is called a new ‘frame’ is allocated on top of the stack. It contains all the variables within the function along with the arguments the function takes. A variable stored on the frame cannot be accessed after the frame goes away(lifetime is lifetime of the frame).\n\n\n\nHeap is a pool of memory that isn’t tied to the stack of the program. This is useful when we want a value to live beyond the frame of the current function’s frame.\nSince allocations from the heap do not go away after the function, we can allocate in one function pass around the pointer to another thread and continue to safely operate of the value in the heap. The pointer has an unconstrained lifetime - its lifetime is however long the program keeps it alive.\n\n\n\nStatic memory is a catch all term for several closely related regions located in the file a program is compiled into. Values in static memory live for the duration of the program.\nStatic memory also holds the variables we define with a static keyword as well as certain constants values like strings.\nThe 'static lifetime does not create a static variable but once a reference with a static lifetime is created, it lives on till the end of the program. Whereever it pionts to might as well be in the static memory."
  },
  {
    "objectID": "rust/async-await.html",
    "href": "rust/async-await.html",
    "title": "Async/Await",
    "section": "",
    "text": "tasks voluntarily give up control to the CPU through a yield operation\ndifferent from preemptive scheduling where the OS forcibly switches between running tasks\n\nBasically comes down to:\nIf I don’t run, I’m gonna let whoever is above me decide who runs next, and it might not be me"
  },
  {
    "objectID": "rust/async-await.html#why",
    "href": "rust/async-await.html#why",
    "title": "Async/Await",
    "section": "Why?",
    "text": "Why?\n\nI/O is costly\nThreads are nice\nBut not too many\nSwitching threads = context switches, costly"
  },
  {
    "objectID": "rust/async-await.html#future-and-asyncawait",
    "href": "rust/async-await.html#future-and-asyncawait",
    "title": "Async/Await",
    "section": "Future and async/await",
    "text": "Future and async/await\n\nAsync/await let us take advantage of cooperative scheduling by allowing us to describe under what circumstances code can make progress and under what circumstances code can yield\nCooperative scheduling also means that you have to be vigilant about running blocking code in a future\n\nsee tokio::task::spawn_blocking\n\nAsync/await is rust is implemented using what is called a Future\nFuture represents a value that is not available yet.\nInstead of waiting for the value to become available, Futures allow the execution to continue till the value is needed.\nFuture has a poll method is used to initiate the resolution of the Future. Rust Futures are lazy.\n\npub trait Future {\n    type Output;\n    fn poll(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output>;\n}\n\n/**\nOutput -> Type of the asynchronous value that the future resolves to.\nPin -> Reference which is pinned in memory\nContext -> Contains information about the Waker(responsible for letting executor\nknow about resolution of the Future)\n**/\n\nAsync/await facilitates the creation of nested Futures to better utilize CPU resources."
  },
  {
    "objectID": "rust/async-await.html#executor",
    "href": "rust/async-await.html#executor",
    "title": "Async/Await",
    "section": "Executor",
    "text": "Executor\n\nSo is it turtles all the way down?\n\nSomething has to hold all our futures\nIt can’t yield, because its a top level Future describing the flow of our application\nSo it kind of checks on all the futures in our application flow\n\nThis is what an executor does in a very basic sense\nExecutor create (e.g. tokio):\n\nprovides lowest resources on network sockets and timers\nprovides the executor loop at the top\nwired up together behind the scenes\ne.g. if we are waiting for a network socket, tokio manages all that for us\n\nThis is what happens when we wrap our Rust main function in tokio::main\n\nit kind bundles up that whole thing into an executor and handles everything to do with the OS for us, so we can focus on application logic and control flow using async await"
  },
  {
    "objectID": "rust/async-await.html#efficiency",
    "href": "rust/async-await.html#efficiency",
    "title": "Async/Await",
    "section": "Efficiency",
    "text": "Efficiency\n\nSpawn:\n\nProblem: async/await runs on 1 thread if you are not spawning anything\nspawning lets us take advantage of parallelism\n\nUnder the hood futures are implemented as state machines that contain the state of all the futures that they contain\n\nthis can become a problem when we are dealing with large states\nfutures become too big\nalternatives\n\nhave state on heap; Box our futures\nuse tokio::spawn, uses pointer to future\n\n\nasync-trait used to have traits with async functions\n\nwhy? Because its not possible for compiler to know size of futures\nasync-trait box that in a pointer for dynamic dispatch"
  },
  {
    "objectID": "rust/async-await.html#sharing-state",
    "href": "rust/async-await.html#sharing-state",
    "title": "Async/Await",
    "section": "Sharing state",
    "text": "Sharing state\n\nsharing state across Futures\n\nArc, Mutex\nclone arc and pass it into futures\n\nTokio also provides a mutex, but it is advised to use the standard library mutex as long as the critical section is short or has an await.\n\nrisk of deadlock\ntokio mutex helps but is slower"
  },
  {
    "objectID": "rust/async-await.html#cancelling-future-execution",
    "href": "rust/async-await.html#cancelling-future-execution",
    "title": "Async/Await",
    "section": "Cancelling Future execution",
    "text": "Cancelling Future execution\n\nCancellation is possible: see select macro tokio\n\nNeed to aware of all the edge cases\n\n\nThreads vs Futures:\n\ngeneral rule of thumb, use threads for compute heavy stuff\nuse async for IO applications"
  },
  {
    "objectID": "rust/async-await.html#resources-and-references",
    "href": "rust/async-await.html#resources-and-references",
    "title": "Async/Await",
    "section": "Resources and References",
    "text": "Resources and References\n\nJon Gjengset deep dive into async/await from an implementation PoV\nJon Gjengset overview of async/await from an application dev PoV\nOS rust section on async/await"
  },
  {
    "objectID": "rust/pointers.html",
    "href": "rust/pointers.html",
    "title": "Smart pointers and Interior Mutability",
    "section": "",
    "text": "Smart pointers, on the other hand, are data structures that act like a pointer but also have additional metadata and capabilities. In other words, they act like pointers but have additional behaviour e.g. - what happens when the smart pointer needs to be dropped - what behaviour to expose to the outside world and how\nSee exercises/code here"
  },
  {
    "objectID": "rust/pointers.html#unsafe-cell",
    "href": "rust/pointers.html#unsafe-cell",
    "title": "Smart pointers and Interior Mutability",
    "section": "Unsafe Cell",
    "text": "Unsafe Cell\nCore primitive for interior mutability in Rust.\nAn usafe primitive. UnsafeCell opts out of the immutability guarantee for &T.\nA shared reference to &UnsafeCell<T> may point to data that is being mutated."
  },
  {
    "objectID": "rust/pointers.html#cell",
    "href": "rust/pointers.html#cell",
    "title": "Smart pointers and Interior Mutability",
    "section": "Cell",
    "text": "Cell\nRust allows shared references: everyone can read ONLY. Rust allows mutable references: ONLY one owner can change things.\nCell is a sharable mutable reference. Sometimes it is required to have multiple references to an object and yet mutate it.\nCell allows us to do this is a single threaded context. Usually used to a flag or an int in a thread local environment.\nCell is copy. Generally used for small types that are Copy."
  },
  {
    "objectID": "rust/pointers.html#refcell",
    "href": "rust/pointers.html#refcell",
    "title": "Smart pointers and Interior Mutability",
    "section": "RefCell",
    "text": "RefCell\nNormally all borrow checks are done at compile time. RefCell allows us to do safe dynamically checked borrowing."
  },
  {
    "objectID": "rust/pointers.html#rc",
    "href": "rust/pointers.html#rc",
    "title": "Smart pointers and Interior Mutability",
    "section": "Rc",
    "text": "Rc\nRc refers to reference counting pionters.\nIt provides a shared ownership of a value of type T, allocating in the heap. Calling a clone method returns a pointer to the same allocation in the heap.\nWhen the last Rc pointer to the allocation is destroyed, the value is dropped.\nSince sharing mutable references is not permitted by default in Rust, we have to put a Cell and Refcell insdie an Rc.\nRc cannot be send between thread."
  },
  {
    "objectID": "rust/pointers.html#thread-safe-version-of-these",
    "href": "rust/pointers.html#thread-safe-version-of-these",
    "title": "Smart pointers and Interior Mutability",
    "section": "Thread safe version of these",
    "text": "Thread safe version of these\n\nCell\nNo thread safe version. Having two threads modify the same reference at the same time is not okay.\n\n\nRefcell -> RwLock\nRwLock is kinda similar in functionality to a RefCell.\nRwLock doesn’t return Options for giving out read and write references. Instead it using blocks the thread if the borrow can’t suceed. When the conditions are met, the operations are allowed.\n\n\nRc -> Arc\nThread safe reference counting pointer. Use CPU atomics to managing the reference count.\nNOTE: There is a cost to using these atomics. That’s why we might want to use Cell, RefCells and Rcs."
  },
  {
    "objectID": "rust/trait-bounds.html",
    "href": "rust/trait-bounds.html",
    "title": "Trait and trait-bounds",
    "section": "",
    "text": "Most Rust types are Sized i.e. they have a size that is known at compile time. Two common exceptions to this are trait objects and slices(e.g dyn Iterator or [u8])\nTheir size depends on some information that is available only when the program is run and not at compile time. That is why they are called dynamically sized traits.\nThe compiler requires types to be Sized nearly everywhere: struct fields, function arguments, return values, variable types and array types. Every single type bound we write has T: Sized by default, unless we opt out.\nThe way to bridge this gap between the unsized and sized types is to place unsized types behind a wide pointer (fat pointer).\n\n\nA wide/fat pointer is like other pointers, but it includes an extra word-sized field that gives additional information required by the compiler to generate reasonable code for working with the pointer.\nWide/fat pointers are Sized Specifically they are twice the size of a usize, one usize to hold the pointer type and another to hold the additional information required by the compiler.\n\nNOTE: Box and Arc also support storing wide/fat pointers. That is why they support T: ?Sized"
  },
  {
    "objectID": "rust/trait-bounds.html#traits-and-trait-bounds",
    "href": "rust/trait-bounds.html#traits-and-trait-bounds",
    "title": "Trait and trait-bounds",
    "section": "Traits and Trait Bounds",
    "text": "Traits and Trait Bounds\nTraits are the glue that allow Rust types to interoperate even though they don’t know about each other at the time they are defined.\n\nHow are generics used in Rust?\nThe compiler replaces the generic types with actual types in the code that involves generics. We are basically telling the compiler to make a copy of that function for each type T it is used with.\n\n\nStatic dispatch\nConsider the code:\nimpl String {\n  pub fn contains(&self, p: impl Pattern) -> bool {\n    p.is_contained_in(self)\n  }\n}\nThe compiler needs a different copy of the function body of each impl Pattern type because it needs to know the address of the is_contained_in function to call it. The CPU needs to be told where to jump and continue execution.\nThis is referred to as static dispatch because the address we are dispatching to is known at compile time.\nThis process of going from a generic type to a non-generic type is called monomorphization.\n\nCost of monomorphization\n\nAll instances of non-generic types must be compiled separately which increases the compile time.\nEach monomorphized function results in its own chunk of machine code, thus making the program larger.\nCPU’s instruction cache is also less effective as instructions are not shared between different instantiations of the a generic type’s methods. It needs to hold multiple copies of effectively the same instructions.\n\n\nOne pattern is to declare a non-generic helper function to perform shared operations."
  },
  {
    "objectID": "rust/trait-bounds.html#dynamic-dispatch",
    "href": "rust/trait-bounds.html#dynamic-dispatch",
    "title": "Trait and trait-bounds",
    "section": "Dynamic Dispatch",
    "text": "Dynamic Dispatch\nEnables code to call a trait method on a generic type without knowing what that type is.\nimpl String {\n  pub fn contains(&self, p: &dyn Pattern) -> bool {\n    p.is_contained_in(self)\n  }\n}\nWe are basically telling that the caller must give two pieces of information: - the address of the pattern - the address of the method is_contained_in\nIn practise the address of the vtable is passed to the method. The vtable contains the address of all the implementations of all the trait’s methods.\nThis allows us to use the same function body regardless of the type of the caller wants to use.\nSee playground example here\n\nTrait objects\nThe combination of a type that implements a trait and its vtable are known as a trait object. Most traits can be turned into trait objects but not all.\nOnly traits which are object-safe can be turned into trait objects.\nTo be object-safe: - none of the traits methods can be generic or use the Self type - the trait cannot have any static methods, since it would be impossible to know which method to call\nUsing the Self: Sized bound imples that Self is not being used through a trait object, because otherwise it would be !Sized. We can place that bound on a trait to require that a trait never uses dynamic dispatch, or it can be placed on a specific method to specify that the method should never be used through a trait object.\n\n\nPros and cons of dynamic dispatch\nPros: - cuts compile time - improve efficiency of CPU instruction cache\nCons: - prevents the compiler from optimizing for specific types - every lookup from the vtable adds a small overhead over calling methods directly\n\n\nChoosing between dynamic and static dispatch\nRule of thumb: Use static dispatch in libraries and dynamic dispatch in you binaries\nWe want to allow the user to decide what kind of dispatch is best for them in a library. Dynamic dispatch forces the users to do the same, whereas with static dispatch they can choose whether to use dynamic dispatch or not.\nFor binaries, we are writing the final code, hence if cleaner code, leaving our generic parameter, quicker compile times at the cost marginal performance sound okay, its a better choice for binaries."
  },
  {
    "objectID": "rust/trait-bounds.html#trait-bounds",
    "href": "rust/trait-bounds.html#trait-bounds",
    "title": "Trait and trait-bounds",
    "section": "Trait bounds",
    "text": "Trait bounds\nBounds can be any type restrictions. They do not need to include generic parameters, types of arguments or local types.\nwhere String: Clone is a valid trait bound.\nwhere io::Error: From<MyError<T>> is also valid. Generic type parameters do not need to appear only on the left side. This is useful to express more intricate trait bounds. It can also save one from needlessly repeating bounds.\ne.g.\nTo construct a HashMap<T,V,S> where keys are some generic tyype T and whose value is usize, we can use:\nwhere HashMap<T,usize,S>: FromIterator\ninstead of\nwhere T:Hash+Eq, S:BuildHasher+Default\nThis also clearly communicates the ‘true’ requirements of the code.\nWe can also write bounds for associated types of types we’re generic over. We can refer to the associated type using the syntax:\n<Type as Trait>::AssocType\nSee: https://doc.rust-lang.org/std/iter/struct.Flatten.html\n\nHigher-ranked trait bounds\nWhen working with generic references to a type, writing bounds requires a generic lifetime parameter that we can use a lifetime for the references.\nSometimes thought, we also want the baility to say that this reference implements this trait for any lifetime. This type of bound is known as a higher-ranked trait bound, is is useful in associations with the Fn trait.\nwher F: for<'a> Fn(&'a T) -> &'a U\nWe are saying that for any lifetime ’a, the bound must hold.\nThe compiler is smart enough to automatically add the for when we write Fn bounds with references like this, which covers the majority of use cases. The explicit form is needed exceedingly rarely.\nExample that implement Debug for any type that can be Iterated over and whose elements are Debug.\nimpl Debug for AnyIterable\n    where for<'a> &'a Self: IntoIterator,\n        for<'a> <&'a Self as IntoIterator>::Item: Debug {\n    fn fmt(&self, f: &mut Formatter) -> Result((), Erro) {\n        f.debug_list().enteries(self).finish()\n    }   \n}"
  },
  {
    "objectID": "rust/trait-bounds.html#marker-traits",
    "href": "rust/trait-bounds.html#marker-traits",
    "title": "Trait and trait-bounds",
    "section": "Marker Traits",
    "text": "Marker Traits\nUsually we use traits to denote functionality that multiple types support e.g a Hash type can be hashed by calling hash. But not all traits are functional.\nMarker traits indicate a property of the implementing type. Marker traits have no methods or associated types, and serve just to tell you that a particular type can or cannot be used in a certain way.\ne.g. A type that is Send is safe to send across thread boundaries. There are no methods associated with this behaviour. It is just a fact about the type.\nstd::marker has a number of these including Send, Sync, Copy, Sized and Unpin\nMost of these (except Copy) are auto-traits. That means that the compiler automatically implements them for types unless the type contains something that does not implement the marker trait.\nMarker traits are important because they allow us to write bounds that capture the tsemantic requirements not directly expressed in the code.\nUnit types (e.g. MyMarker) serve a function similar to marker types. They hold no data and have no methods. They are useful for marking a type in a particular state."
  },
  {
    "objectID": "rust/declarative_macros.html",
    "href": "rust/declarative_macros.html",
    "title": "Declerative macros",
    "section": "",
    "text": "See for a simple exercise with macros. Macros are more about metaprogramming. Can be used to map Rust expression to generate or run code. Kind of like match, but for Rust expressions."
  },
  {
    "objectID": "rust/declarative_macros.html#declaring",
    "href": "rust/declarative_macros.html#declaring",
    "title": "Declerative macros",
    "section": "Declaring",
    "text": "Declaring\n    macro_rules! avec {\n        () => {};\n    }\nWe can supply any arguments to the macro definition as if it were a function e.g. \n    macro_rules! avec {\n        ($arg1: ty, $arg2:expr, $arg3: path) => {};\n    }\nBut, we don’t have to.\nRust allows us to write whatever we want as syntax pattern as long as its syntactically valid Rust. It should be parsed. And the output has to be valid Rust grammar. That means its doesn’t need to compile, but it must be comprised of valid Rust syntax. e.g.\n    macro_rules! avec {\n        ($arg1: ty => $arg2:expr; $arg3: path) => {};\n    }\nNOTE: Rust macros are not allowed to use values outside their own scope."
  },
  {
    "objectID": "rust/declarative_macros.html#using-macros",
    "href": "rust/declarative_macros.html#using-macros",
    "title": "Declerative macros",
    "section": "using macros",
    "text": "using macros\n    macro_rules! avec {\n        () => {};\n    }\nWe can use any brackets, because there is no way to specify what brackets we expect in current syntax.\nSO its up to the user to use what he wants.\n avec!();\n avec![];\n avec! {}"
  },
  {
    "objectID": "rust/declarative_macros.html#cargo-expand",
    "href": "rust/declarative_macros.html#cargo-expand",
    "title": "Declerative macros",
    "section": "Cargo expand",
    "text": "Cargo expand\nHandy tool to expand all the macros in out code.\nmacro_rules! avec {\n    ($arg1: ty => $arg2:ident) => {\n        type $arg2 = $arg1; \n    };\n}\n\n\navec!{u32 => AlsoU32}\nexpands to:\n#![feature(prelude_import)]\n#[prelude_import]\nuse std::prelude::rust_2021::*;\n#[macro_use]\nextern crate std;\ntype AlsoU32 = u32;"
  },
  {
    "objectID": "rust/declarative_macros.html#patterns",
    "href": "rust/declarative_macros.html#patterns",
    "title": "Declerative macros",
    "section": "Patterns",
    "text": "Patterns\nWe can specify patterns for repitition logic:\n    // $($elem:expr),+: 1 or more of this pattern\n    // $(,)?: Zero or one trailing comma\n    ($($elem:expr),+ $(,)?) => {\n        // We want this to be a block so that when we\n        // do `let x = avec![..] cargo doesn't get mad\n        {\n            let mut vs = Vec::new();\n            // Repeat inside these parens the same num of time\n            // as the pattern that had 'elem' in it\n            $(vs.push($elem);)*\n            vs\n        }\n    };"
  },
  {
    "objectID": "rust/ownership.html",
    "href": "rust/ownership.html",
    "title": "Ownership, Borrowing and Lifetimes",
    "section": "",
    "text": "All rust values have a single owner. This means that exactly one location(usually a scope) is responsible for deallocating each value.\nIf the value is moved, e.g. by assigning it to a new variable, pushing it to a vector or placing it on the heap, the ownership changes.\nThe owner has the responsibility of cleanup after a value is no longer needed. This is called dropping, and happens automatically when the variable that holds the value is no longer in scope."
  },
  {
    "objectID": "rust/ownership.html#borrowing-and-lifetimes",
    "href": "rust/ownership.html#borrowing-and-lifetimes",
    "title": "Ownership, Borrowing and Lifetimes",
    "section": "Borrowing and Lifetimes",
    "text": "Borrowing and Lifetimes\nRust allows owners of a value to lend it out to others, without giving up ownership, through references.\nReferences are pointers with an additional contract for how they can be used. Whether they are exclusive references or whether they are shared references.\n\nShared References (&T)\nValues behind shared references are not mutable. There can be no modification, reassignment or casting to a mutable reference. The value that lives behind a shared reference does not change while the reference is alive.\n\n\nMutable References (&mut T)\nThere is no other thread that is accessing this reference whether through a shared reference or through a mutable one. Mutable references are exclusive.\nA mutable reference allows us to mutate only the memory location that the reference points to. Whether we can mutate values that lie beyond the immediate reference depends on the methods provided by the type that lies between.\nWe can change the value of y, by changing what it references, but not the value at the reference.\n    let x = 1;\n    let a = 2;\n    let mut y = &x;\n    let z = &mut y;\n    \n    y = &a;\n    \n    *y = 42;\n    \n    /*\n         *y = 42;\n         ^^^^^^^ `y` is a `&` reference, so the data it refers to cannot be written\n    */\nWe can reference held in y, through z.\n    let x = 1;\n    let a = 2;\n    let mut y = &x;\n    let z = &mut y;\n    \n    *z = &x; // Works!\nWe cannot change z itself in the above example.\n\nNOTE The primary difference between an mutable reference and an owned value is that the owner is responsible for dropping the value. Another ceaveat is that: if we move the value behind the mutable reference then one must leave another value in its place\n\nThis is because there would be no value for the owner to drop otherwise.\nfn replace(b: &mut Box<i32>) {\n    // let was = *b;\n    /*\n    error[E0507]: cannot move out of `*b` which is behind a mutable reference\n    */\n    // let was = std::mem::take(b);\n    // *b = was; // Works!!\n    \n    let mut a = Box::new(42);\n    std::mem::swap(b, &mut a);\n}\n\nfn main() {\n    let mut s = Box::new(1);\n    \n    replace(&mut s);\n    \n    assert_eq!(*s, 42);\n}"
  },
  {
    "objectID": "fastai/lesson_1.html",
    "href": "fastai/lesson_1.html",
    "title": "Is it a duck or a swan?",
    "section": "",
    "text": "Install dependencies\n\n!pip install -Uqq fastai duckduckgo_search\n\n\n\nDefine a function to search for images on DDG. Search for 90 images by default.\n\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\n\ndef search_images(term, max_images=90):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\n\n\nLets see the an example of the URL we find using the above function\n\nurls = search_images('duck', max_images=1)\nurls[0]\n\nSearching for 'duck'\n\n\n'http://3.bp.blogspot.com/--XA3iMvaJLY/Tw_GykPs-eI/AAAAAAAAEgU/EmFKS7Cz5xQ/s1600/Duck-04.jpg'\n\n\n\n\nWhat does this image look like? Is it actually a duck?\n\nfrom fastdownload import download_url\ndest = 'duck.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\n\n\n\n\nHow about a swan?\n\ndownload_url(search_images('swan', max_images=1)[0], 'swan.jpg', show_progress=False)\nImage.open('swan.jpg').to_thumb(256,256)\n\nSearching for 'swan'\n\n\n\n\n\n\n\nLooks like we are on the right path. So go ahead and download 90 of each. Might take a bit of time.\n\nsearches = 'duck','swan'\npath = Path('duck_or_swan')\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(30)  # Pause between searches to avoid over-loading server\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSearching for 'duck photo'\nSearching for 'swan photo'\n\n\n\n\nRemove images that didn’t get downloaded properly\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n1\n\n\n\n\nThe easiest way to use FastAI is to use define a DataBlock. We load the data from the path.\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n\nFine tune the pre-trained resnet18 model for our data.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n/Users/bnabi/miniforge3/envs/invokeai/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  warnings.warn(\n/Users/bnabi/miniforge3/envs/invokeai/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.222246\n      0.440960\n      0.290323\n      00:04\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.402388\n      0.356703\n      0.193548\n      00:05\n    \n    \n      1\n      0.249177\n      0.256310\n      0.064516\n      00:05\n    \n    \n      2\n      0.192781\n      0.251938\n      0.032258\n      00:05\n    \n  \n\n\n\n\n\nTesting the images\n\nbird,_,probs = learn.predict(PILImage.create('duck.jpg'))\nImage.open('duck.jpg').to_thumb(256,256)\nprint(f\"This is a: {bird}.\")\nprint(f\"Probability it's a duck: {probs[0]:.4f}\")\nprint(f\"Probability it's a swan: {probs[1]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: duck.\nProbability it's a duck: 0.9990\nProbability it's a swan: 0.0010\n\n\n\nbird,_,probs = learn.predict(PILImage.create('swan.jpg'))\nImage.open('duck.jpg').to_thumb(256,256)\nprint(f\"This is a: {bird}.\")\nprint(f\"Probability it's a duck: {probs[0]:.4f}\")\nprint(f\"Probability it's a swan: {probs[1]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: swan.\nProbability it's a duck: 0.0006\nProbability it's a swan: 0.9994"
  }
]